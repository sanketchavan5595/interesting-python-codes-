{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the MagicBricks for getting flats information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make sure the weboage has the following info**\n",
    "- BHKs \n",
    "- address\n",
    "- price\n",
    "- furnished or not \n",
    "- status \n",
    "- transaction \n",
    "- builder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "def flat_scraper_df(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # BHKs \n",
    "    bhk = soup.find_all('span', {'class': 'm-srp-card__title__bhk'})\n",
    "    bhks = []\n",
    "    for b in bhk:\n",
    "        bhks.append(b.text.strip())\n",
    "        \n",
    "    # prices\n",
    "    price = soup.find_all('div', {'class': 'm-srp-card__price'})\n",
    "    prices = []\n",
    "    for p in price:\n",
    "        prices.append(p.text)\n",
    "\n",
    "    # addresses\n",
    "    add = soup.find_all('span', {'class': 'm-srp-card__title'})\n",
    "    place = []\n",
    "    for a in add:\n",
    "        place.append(a.text.strip().split('\\n')[-1])\n",
    "        \n",
    "    items = soup.find_all('div', {'class': 'm-srp-card__summary__item'})\n",
    "        \n",
    "    # transaction\n",
    "    transaction = []\n",
    "    for i in items:\n",
    "        if i.find('div', {'class': 'm-srp-card__summary__title'}).text == 'transaction':\n",
    "            transaction.append(i.find('div', {'class': 'm-srp-card__summary__title'}).find_next().text.strip())\n",
    "    \n",
    "\n",
    "    # furnishing\n",
    "    furnishing = []\n",
    "    for i in items:\n",
    "        if i.find('div', {'class': 'm-srp-card__summary__title'}).text == 'furnishing':\n",
    "            furnishing.append(i.find('div', {'class': 'm-srp-card__summary__title'}).find_next().text.strip())\n",
    "    \n",
    "    \n",
    "    # society\n",
    "    society = []\n",
    "    for i in items:\n",
    "        if i.find('div', {'class': 'm-srp-card__summary__title'}).text == 'society':\n",
    "            society.append(i.find('div', {'class': 'm-srp-card__summary__title'}).find_next().text.strip())\n",
    "\n",
    "    # builder\n",
    "    builder = []\n",
    "    for b in soup.find_all('div', {'class': 'm-srp-card__advertiser__name'}):\n",
    "        builder.append(b.text.strip())\n",
    "        \n",
    "        \n",
    "        \n",
    "    d = {\n",
    "    'bhks': bhks,\n",
    "    'prices': prices,\n",
    "    'society': society,\n",
    "    'place': place,\n",
    "    'transaction': transaction,\n",
    "    'furnishing': furnishing,\n",
    "    'builder': builder\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        return pd.DataFrame(d)\n",
    "    except:\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = input(\"Enter the url: \")\n",
    "df = flat_scraper_df(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
